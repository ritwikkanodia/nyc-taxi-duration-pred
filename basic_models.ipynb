{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import zipfile\nimport time \n\nfrom sklearn.cluster import KMeans ,AgglomerativeClustering\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.metrics import classification_report, confusion_matrix \nfrom sklearn.metrics import mean_squared_error as MSE\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"files = [\"../input/nyc-taxi-trip-duration/train.zip\", \"../input/nyc-taxi-trip-duration/test.zip\", \"../input/nyc-taxi-trip-duration/sample_submission.zip\"]\nfor file in files:\n    with zipfile.ZipFile(file,\"r\") as zip_ref:\n        zip_ref.extractall(\"./nyc-taxi-trip-duration/\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_outliers(df):\n    # Refer to EDA notebook for the reasoning for choosing these specific filters\n    df = df.query('trip_duration < 5900')\n    df = df.query('passenger_count > 0')\n    df = df.query('pickup_latitude > -100')\n    df = df.query('pickup_latitude < 50')\n    \n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def encode_categorical_data(df, test):\n\n    df = pd.concat([df, pd.get_dummies(df['store_and_fwd_flag'])], axis=1)\n    test = pd.concat([test, pd.get_dummies(test['store_and_fwd_flag'])], axis=1)\n    df = df.drop(['store_and_fwd_flag'], axis=1)\n\n    df = pd.concat([df, pd.get_dummies(df['vendor_id'])], axis=1)\n    test = pd.concat([test, pd.get_dummies(test['vendor_id'])], axis=1)\n    df = df.drop(['vendor_id'], axis=1)\n\n    return df, test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convert_obj_to_ts(df, test):\n\n    df['pickup_datetime'] = pd.to_datetime(df.pickup_datetime)\n    test['pickup_datetime'] = pd.to_datetime(test.pickup_datetime)\n\n    df = df.drop(['dropoff_datetime'], axis=1)\n\n    return df, test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_date_features(df):\n\n    df['month'] = df.pickup_datetime.dt.month\n    df['week'] = df.pickup_datetime.dt.week\n    df['weekday'] = df.pickup_datetime.dt.weekday\n    df['hour'] = df.pickup_datetime.dt.hour\n    df['minute'] = df.pickup_datetime.dt.minute\n    df['minute_oftheday'] = df['hour'] * 60 + df['minute']\n    df.drop(['minute'], axis=1, inplace=True)\n\n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ft_haversine_distance(lat1, lng1, lat2, lng2):\n    lat1, lng1, lat2, lng2 = map(np.radians, (lat1, lng1, lat2, lng2))\n    AVG_EARTH_RADIUS = 6371\n    lat = lat2 - lat1\n    lng = lng2 - lng1\n    d = np.sin(lat * 0.5) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(lng * 0.5) ** 2\n    h = 2 * AVG_EARTH_RADIUS * np.arcsin(np.sqrt(d))\n    return h","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_distance_features(df):\n\n    df['distance'] = ft_haversine_distance(\n                            df['pickup_latitude'].values,\n                            df['pickup_longitude'].values, \n                            df['dropoff_latitude'].values,\n                            df['dropoff_longitude'].values\n                        )\n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ft_degree(lat1, lng1, lat2, lng2):\n\n    AVG_EARTH_RADIUS = 6371\n    lng_delta_rad = np.radians(lng2 - lng1)\n    lat1, lng1, lat2, lng2 = map(np.radians, (lat1, lng1, lat2, lng2))\n    y = np.sin(lng_delta_rad) * np.cos(lat2)\n    x = np.cos(lat1) * np.sin(lat2) - np.sin(lat1) * np.cos(lat2) * np.cos(lng_delta_rad)\n    return np.degrees(np.arctan2(y, x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_direction_features(df):\n    df['direction'] = ft_degree(\n                            df['pickup_latitude'].values,\n                            df['pickup_longitude'].values,\n                            df['dropoff_latitude'].values,\n                            df['dropoff_longitude'].values\n                        )\n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def data_pre_feat_engg(df):\n\n    df = df.query('distance < 200')\n    df['speed'] = df.distance / df.trip_duration\n    df = df.query('speed < 30')\n    df = df.drop(['speed'], axis=1)\n\n    df['trip_duration'] = np.log(df['trip_duration'].values)\n    y = df[\"trip_duration\"]\n    df = df.drop([\"trip_duration\"], axis=1)\n    df = df.drop(['id'], axis=1)\n    X = df\n    \n    return X, y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_and_clean():\n\n    df = pd.read_csv(\"./nyc-taxi-trip-duration/train.csv\")\n    test = pd.read_csv(\"./nyc-taxi-trip-duration/test.csv\")\n\n    df = remove_outliers(df)\n    df, test = encode_categorical_data(df, test)\n    df, test = convert_obj_to_ts(df, test)\n    df, test = create_date_features(df), create_date_features(test)\n    \n    df.drop(['pickup_datetime'], axis=1, inplace=True)\n\n    df, test = create_distance_features(df), create_distance_features(test)\n    df, test = create_direction_features(df), create_direction_features(test)\n\n    X, y = data_pre_feat_engg(df)\n\n    return X, y, test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_test_train_split(X, y):\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n    return X_train, X_test, y_train, y_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X, y, test = read_and_clean()\ntest_columns = X.columns\nX_train, X_test, y_train, y_test = get_test_train_split(X, y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_submission_df(test, preds):\n    sub_df = pd.DataFrame()\n    sub_df['id'] = test.id\n    sub_df['trip_duration'] = preds\n\n    return sub_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## KNN","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsRegressor\nneigh = KNeighborsRegressor(n_neighbors=20, weights='distance')\nneigh.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = np.exp(neigh.predict(test[test_columns]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df = create_submission_df(test, preds)\nsub_df.to_csv('submission_KNN_{}.csv'.format(time.strftime(\"%Y%m%d%H%M\")), index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Stacking","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import LinearSVR\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.ensemble import RandomForestRegressor\n\nestimators = [('lr', RidgeCV()), ('svr', LinearSVR())]\nsReg = StackingRegressor(estimators=estimators, final_estimator=RandomForestRegressor(n_estimators=10,random_state=42))\nsReg.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(sReg.score(X_train, y_train), sReg.score(X_test, y_test))\nprint(np.sqrt(MSE(y_test, sReg.predict(X_test))))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = np.exp(sReg.predict(test[test_columns]))\n\nsub_df = create_submission_df(test, preds)\nsub_df.to_csv('submission_sReg_{}.csv'.format(time.strftime(\"%Y%m%d%H%M\")), index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Bagging Regressor","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVR\nfrom sklearn.ensemble import BaggingRegressor\n\nbagR = BaggingRegressor(base_estimator=SVR(), n_estimators=100)\nbagR.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(bagR.score(X_train, y_train), bagR.score(X_test, y_test))\nprint(np.sqrt(MSE(y_test, bagR.predict(X_test))))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = np.exp(bagR.predict(test[test_columns]))\n\nsub_df = create_submission_df(test, preds)\nsub_df.to_csv('submission_bagR_{}.csv'.format(time.strftime(\"%Y%m%d%H%M\")), index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## AdaBoost","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import AdaBoostRegressor\n\nab = AdaBoostRegressor(n_estimators=100)\nab.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(ab.score(X_train, y_train), ab.score(X_test, y_test))\nprint(np.sqrt(MSE(y_test, ab.predict(X_test))))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = np.exp(ab.predict(test[test_columns]))\n\nsub_df = create_submission_df(test, preds)\nsub_df.to_csv('submission_ab_{}.csv'.format(time.strftime(\"%Y%m%d%H%M\")), index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Decision Tree","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\ndt = DecisionTreeRegressor(max_depth=13)\ndt.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(dt.score(X_train, y_train), dt.score(X_test, y_test))\nprint(np.sqrt(MSE(y_test, dt.predict(X_test))))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = np.exp(dt.predict(test[test_columns]))\n\nsub_df = create_submission_df(test, preds)\nsub_df.to_csv('submission_dt_max_{}.csv'.format(time.strftime(\"%Y%m%d%H%M\")), index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import tree\ntree.plot_tree(dt)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Random Forest","metadata":{}},{"cell_type":"code","source":"%%time\n# Try RandomForest\nfrom sklearn.ensemble import RandomForestRegressor\n\nrf = RandomForestRegressor(verbose= 100, max_depth=10, max_features = 0.7, n_estimators=10, n_jobs=-1)\nrf.fit(X_train, y_train)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(rf.score(X_train, y_train), rf.score(X_test, y_test))\nprint(np.sqrt(MSE(y_test, rf.predict(X_test))))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_imp = pd.Series(rf.feature_importances_,index=X.columns).sort_values(ascending=False)\nfeature_imp","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\n# Creating a bar plot\nsns.barplot(x=feature_imp, y=feature_imp.index)\n# Add labels to your graph\nplt.xlabel('Feature Importance Score')\nplt.ylabel('Features')\nplt.title(\"Visualizing Important Features\")\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = np.exp(rf.predict(test[test_columns]))\n\nsub_df = create_submission_df(test, preds)\nsub_df.to_csv('submission_random_max_{}.csv'.format(time.strftime(\"%Y%m%d%H%M\")), index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Multi-layer Perceptron","metadata":{}},{"cell_type":"code","source":"mlp = MLPRegressor(hidden_layer_sizes=(64, 64, 64), max_iter=1000, verbose = 100, early_stopping =  True)  \nmlp.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(mlp.score(X_train, y_train), mlp.score(X_test, y_test))\nprint(np.sqrt(MSE(y_test, mlp.predict(X_test))))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = np.exp(mlp.predict(test[test_columns]))\n\nsub_df = create_submission_df(test, preds)\nsub_df.to_csv('submission_mlp_{}.csv'.format(time.strftime(\"%Y%m%d%H%M\")), index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Linear Regression","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nlp = LinearRegression()\nlp.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(lp.score(X_train, y_train), lp.score(X_test, y_test))\nprint(np.sqrt(MSE(y_test, lp.predict(X_test))))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = np.exp(lp.predict(test[test_columns]))\n\nsub_df = create_submission_df(test, preds)\nsub_df.to_csv('submission_lp_{}.csv'.format(time.strftime(\"%Y%m%d%H%M\")), index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Linear Ridge","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import Ridge\nr = Ridge(alpha=0.1)\nr.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(r.score(X_train, y_train), r.score(X_test, y_test))\nprint(np.sqrt(MSE(y_test, r.predict(X_test))))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = np.exp(r.predict(test[test_columns]))\n\nsub_df = create_submission_df(test, preds)\nsub_df.to_csv('submission_r_{}.csv'.format(time.strftime(\"%Y%m%d%H%M\")), index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Bayesian Linear Ridge","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import BayesianRidge\nbr = BayesianRidge()\nbr.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(br.score(X_train, y_train), br.score(X_test, y_test))\nprint(np.sqrt(MSE(y_test, br.predict(X_test))))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = np.exp(br.predict(test[test_columns]))\n\nsub_df = create_submission_df(test, preds)\nsub_df.to_csv('submission_br_{}.csv'.format(time.strftime(\"%Y%m%d%H%M\")), index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Deep Neural Network","metadata":{}},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Dense(16, input_dim=16, activation='relu'))\nmodel.add(Dense(12, activation='relu'))\nmodel.add(Dense(12, activation='relu'))\nmodel.add(Dense(12, activation='relu'))\nmodel.add(Dense(1, activation='linear'))\n# compile the keras model\nmodel.compile(loss='mse',  optimizer='adam', metrics=['mae'])\n# fit the keras model on the dataset\nmodel.fit(X_train, y_train, epochs=10, batch_size=32)\n# evaluate the keras model\n_, accuracy = model.evaluate(X_test, y_test)\nprint('Accuracy: %.2f' % (accuracy*100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(np.sqrt(MSE(y_test, model.predict(X_test))))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = np.exp(model.predict(test[test_columns]))\n\nsub_df = create_submission_df(test, preds)\nsub_df.to_csv('submission_dnn_{}.csv'.format(time.strftime(\"%Y%m%d%H%M\")), index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## DNN + Random Forest","metadata":{}},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Dense(16, input_dim=16, activation='relu'))\nmodel.add(Dense(12, activation='relu'))\nmodel.add(Dense(12, activation='relu'))\nmodel.add(Dense(12, activation='relu', name='my_dense'))\nmodel.add(Dense(8, activation='relu'))\nmodel.add(Dense(1, activation='linear'))\n# compile the keras model\nmodel.compile(loss='mse',  optimizer='adam', metrics=['mae'])\n# fit the keras model on the dataset\nmodel.fit(X_train, y_train, epochs=10, batch_size=32)\n# evaluate the keras model\n_, accuracy = model.evaluate(X_test, y_test)\nprint('Accuracy: %.2f' % (accuracy*100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import Model\nlayer_name='my_dense'\nintermediate_layer_model = Model(inputs=model.input,\n                                 outputs=model.get_layer(layer_name).output)\n\nintermediate_layer_model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"intermediate_output = intermediate_layer_model.predict(X_train) \nintermediate_output = pd.DataFrame(data=intermediate_output)\n\nintermediate_test_output = intermediate_layer_model.predict(X_test) \nintermediate_test_output = pd.DataFrame(data=intermediate_test_output)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\nrf = RandomForestRegressor(verbose= 10,max_depth=10, max_features = 1.0, n_estimators=10, n_jobs=-1)\nrf.fit(intermediate_output, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(rf.score(intermediate_output, y_train), rf.score(intermediate_test_output, y_test))\nprint(np.sqrt(MSE(y_test, rf.predict(intermediate_test_output))))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"intermediate_test = intermediate_layer_model.predict(test[test_columns]) \nintermediate_test = pd.DataFrame(data=intermediate_test)\n\npreds = np.exp(rf.predict(intermediate_test))\n\nsub_df = create_submission_df(test, preds)\nsub_df.to_csv('submission_dnn_rf_{}.csv'.format(time.strftime(\"%Y%m%d%H%M\")), index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}