{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom datetime import timedelta\nimport datetime as dt\n\ndef remove_outliers(df):\n    # Refer to EDA notebook for the reasoning for choosing these specific filters\n    df = df.query('trip_duration < 5900')\n    df = df.query('passenger_count > 0')\n    df = df.query('pickup_latitude > -100')\n    df = df.query('pickup_latitude < 50')\n    df['trip_duration'] = np.log(df['trip_duration'].values)\n\n    return df\n\ndef encode_categorical_data(df, test):\n\n    df = pd.concat([df, pd.get_dummies(df['store_and_fwd_flag'])], axis=1)\n    test = pd.concat([test, pd.get_dummies(test['store_and_fwd_flag'])], axis=1)\n    df = df.drop(['store_and_fwd_flag'], axis=1)\n\n    df = pd.concat([df, pd.get_dummies(df['vendor_id'])], axis=1)\n    test = pd.concat([test, pd.get_dummies(test['vendor_id'])], axis=1)\n    df = df.drop(['vendor_id'], axis=1)\n\n    return df, test\n\ndef convert_obj_to_ts(df, test):\n\n    df['pickup_datetime'] = pd.to_datetime(df.pickup_datetime)\n    test['pickup_datetime'] = pd.to_datetime(test.pickup_datetime)\n\n    df = df.drop(['dropoff_datetime'], axis=1)\n\n    return df, test\n\ndef create_date_features(df):\n\n    df['month'] = df.pickup_datetime.dt.month\n    df['week'] = df.pickup_datetime.dt.week\n    df['weekday'] = df.pickup_datetime.dt.weekday\n    df['hour'] = df.pickup_datetime.dt.hour\n    df['minute'] = df.pickup_datetime.dt.minute\n    df['minute_oftheday'] = df['hour'] * 60 + df['minute']\n    df.drop(['minute'], axis=1, inplace=True)\n\n    return df\n\ndef ft_haversine_distance(lat1, lng1, lat2, lng2):\n    lat1, lng1, lat2, lng2 = map(np.radians, (lat1, lng1, lat2, lng2))\n    AVG_EARTH_RADIUS = 6371\n    lat = lat2 - lat1\n    lng = lng2 - lng1\n    d = np.sin(lat * 0.5) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(lng * 0.5) ** 2\n    h = 2 * AVG_EARTH_RADIUS * np.arcsin(np.sqrt(d))\n    return h\n\ndef create_distance_features(df):\n\n    df['distance'] = ft_haversine_distance(\n                            df['pickup_latitude'].values,\n                            df['pickup_longitude'].values, \n                            df['dropoff_latitude'].values,\n                            df['dropoff_longitude'].values\n                        )\n    return df\n\ndef ft_degree(lat1, lng1, lat2, lng2):\n\n    AVG_EARTH_RADIUS = 6371\n    lng_delta_rad = np.radians(lng2 - lng1)\n    lat1, lng1, lat2, lng2 = map(np.radians, (lat1, lng1, lat2, lng2))\n    y = np.sin(lng_delta_rad) * np.cos(lat2)\n    x = np.cos(lat1) * np.sin(lat2) - np.sin(lat1) * np.cos(lat2) * np.cos(lng_delta_rad)\n    return np.degrees(np.arctan2(y, x))\n\ndef create_direction_features(df):\n    df['direction'] = ft_degree(\n                            df['pickup_latitude'].values,\n                            df['pickup_longitude'].values,\n                            df['dropoff_latitude'].values,\n                            df['dropoff_longitude'].values\n                        )\n    return df\n\ndef data_pre_feat_engg(df):\n\n    df = df.query('distance < 200')\n    df['speed'] = df.distance / df.trip_duration\n    df = df.query('speed < 30')\n    df = df.drop(['speed'], axis=1)\n    y = df[\"trip_duration\"]\n    df = df.drop([\"trip_duration\"], axis=1)\n    df = df.drop(['id'], axis=1)\n    X = df\n    \n    return X, y\n\n\ndef main():\n\n    df = pd.read_csv('../input/nyc-taxi-trip-duration/train.zip')\n    test = pd.read_csv('../input/nyc-taxi-trip-duration/test.zip')\n\n    df = remove_outliers(df)\n    df, test = encode_categorical_data(df, test)\n    df, test = convert_obj_to_ts(df, test)\n    df, test = create_date_features(df), create_date_features(test)\n\n    df.drop(['pickup_datetime'], axis=1, inplace=True)\n\n    df, test = create_distance_features(df), create_distance_features(test)\n    df, test = create_direction_features(df), create_direction_features(test)\n    \n    fr1 = pd.read_csv('../input/new-york-city-taxi-with-osrm/fastest_routes_train_part_1.csv', usecols=['id', 'total_distance', 'total_travel_time',  'number_of_steps', ])\n    fr2 = pd.read_csv('../input/new-york-city-taxi-with-osrm/fastest_routes_train_part_2.csv', usecols=['id', 'total_distance', 'total_travel_time', 'number_of_steps'])\n    test_street_info = pd.read_csv('../input/new-york-city-taxi-with-osrm/fastest_routes_test.csv',\n                                   usecols=['id', 'total_distance', 'total_travel_time', 'number_of_steps'])\n    \n    train_street_info = pd.concat((fr1, fr2))\n    df = df.merge(train_street_info, how='left', on='id')\n    test = test.merge(test_street_info, how='left', on='id')  \n#     df['log_trip_duration'] = np.log(df['trip_duration'].values + 1)  \n    \n#     do_not_use_for_training = ['id', 'log_trip_duration', 'trip_duration', 'dropoff_datetime', 'pickup_date', \n#                                'pickup_datetime', 'date']\n#     feature_names = [f for f in df.columns if f not in do_not_use_for_training]\n    \n#     df = df[feature_names].values\n\n    X, y = data_pre_feat_engg(df)\n    \n\n    return X, y, test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\nimport time\nimport pandas as pd\nimport numpy as np\nimport lightgbm as lgb\nimport xgboost as xgb\n# import catboost as ctb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\n# from data_preprocessing import main\n\n# with open('lightgbm_config.json') as json_file:\n#     lgb_config = json.load(json_file)\n\nlgb_config = {\n    \"learning_rate\": 0.1,\n    \"max_depth\": 30,\n    \"num_leaves\": 1000, \n    \"objective\": \"regression\",\n    \"feature_fraction\": 0.8,\n    \"bagging_fraction\": 0.5,\n    \"max_bin\": 2000,\n    \"verbose\":2\n}\n\nxgb_config = {\n    \"booster\": \"gbtree\",\n    \"objective\": \"reg:squarederror\",\n    \"learning_rate\": 0.07,\n    \"max_depth\": 16,\n    \"subsample\": 0.9,\n    \"colsample_bytree\": 0.7,\n    \"colsample_bylevel\": 0.7,\n    \"verbosity\": 2\n}\n\n# with open('xgboost_config.json') as json_file:\n#     xgb_config = json.load(json_file)\n\ndef get_test_train_split(X, y):\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n    return X_train, X_test, y_train, y_test\n\ndef lgb_train_loop(X, y):\n    df = lgb.Dataset(X, y)\n    lgb_model = lgb.train(lgb_config, df, num_boost_round=1500)\n\n    return lgb_model\n\ndef xgb_train_loop(X,y):\n    df = xgb.DMatrix(X, y)\n    xgb_model = xgb.train(xgb_config, df, num_boost_round=200)\n\n    return xgb_model\n\ndef get_ensemble_predictions(lgb_model, xgb_model, test, test_columns):\n    xgb_preds = xgb_model.predict(xgb.DMatrix(test[test_columns]))\n    lgb_preds = lgb_model.predict(test[test_columns])\n\n    pred_xgb = np.exp(xgb_preds)\n    pred_lgb = np.exp(lgb_preds)\n\n    ensemble_preds = (0.6*pred_lgb + 0.4*pred_xgb)\n\n    return ensemble_preds\n\ndef create_submission_df(test, ensemble_preds):\n    sub_df = pd.DataFrame()\n    sub_df['id'] = test.id\n    sub_df['trip_duration'] = ensemble_preds\n\n    return sub_df\n\nif __name__ == '__main__':\n\n    # get preprocessed data\n    X, y, test = main()\n    test_columns = X.columns\n    X_train, X_test, y_train, y_test = get_test_train_split(X, y)\n    \n#     lgb_model = lgb_train_loop(X, y)\n#     xgb_model = xgb_train_loop(X, y)\n\n#     ensemble_preds = get_ensemble_predictions(lgb_model, xgb_model, test, test_columns)\n\n#     sub_df = create_submission_df(test, ensemble_preds)\n#     sub_df.to_csv('submission_{}.csv'.format(time.strftime(\"%Y%m%d%H%M\")), index=False)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgb_model = lgb_train_loop(X, y)\nxgb_model = xgb_train_loop(X, y)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_ensemble_predictions(lgb_model, xgb_model, test, test_columns):\n    xgb_preds = xgb_model.predict(xgb.DMatrix(test[test_columns]))\n    lgb_preds = lgb_model.predict(test[test_columns])\n\n    pred_xgb = np.exp(xgb_preds)\n    pred_lgb = np.exp(lgb_preds)\n\n    ensemble_preds = (0.6*pred_lgb + 0.4*pred_xgb)\n#     ensemble_preds = pred_lgb\n\n\n    return ensemble_preds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ensemble_preds = get_ensemble_predictions(lgb_model, xgb_model, test, test_columns)\nsub_df = create_submission_df(test, ensemble_preds)\nsub_df.to_csv('submission_final_ensemble_wa_{}.csv'.format(time.strftime(\"%Y%m%d%H%M\")), index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"explainer = shap.TreeExplainer(model)\nshap_values = explainer.shap_values(test[test_columns])\nshap.summary_plot(shap_values, test[test_columns], feature_names = X.columns)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import catboost as ctb","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from catboost import CatBoostRegressor","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = CatBoostRegressor(random_seed=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = CatBoostRegressor(eval_metric='RMSE',random_seed=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(X, y, verbose=2)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = model.predict(test[test_columns])\npreds = np.exp(preds)\nsub_df = pd.DataFrame()\nsub_df['id'] = test.id\nsub_df['trip_duration'] = preds\nsub_df.to_csv('submission_final_catboost_{}.csv'.format(time.strftime(\"%Y%m%d%H%M\")), index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import catboost","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = catboost.Pool(X_train, y_train) \ntest_dataset = catboost.Pool(X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = catboost.CatBoostRegressor(loss_function='RMSE')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid = {'iterations': [1000],\n        'learning_rate': [0.03],\n        'depth': [8, 10],\n        'l2_leaf_reg': [0.2, 0.5, 1]}\nmodel.grid_search(grid, train_dataset)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = model.predict(X_test)\nrmse = (np.sqrt(mean_squared_error(y_test, pred)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shap\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"explainer = shap.TreeExplainer(model)\nshap_values = explainer.shap_values(test[test_columns])\nshap.summary_plot(shap_values, test[test_columns], feature_names = X.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_xgb = np.exp(preds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_xgb","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_preds = xgb_model.predict(xgb.DMatrix(test[test_columns]))\nlgb_preds = lgb_model.predict(test[test_columns])\n\npred_xgb = np.exp(xgb_preds)\npred_lgb = np.exp(lgb_preds)\n\nensemble_preds = (0.7*pred_lgb + 0.3*pred_xgb)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df = pd.DataFrame()\nsub_df['id'] = test.id\nsub_df['trip_duration'] = ensemble_preds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df.to_csv('submission_{}.csv'.format(time.strftime(\"%Y%m%d%H%M\")), index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}